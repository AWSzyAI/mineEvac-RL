{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5648d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | 319      |\n",
      "| time/              |          |\n",
      "|    fps             | 13779    |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 319         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 6373        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009200614 |\n",
      "|    clip_fraction        | 0.0307      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | -0.00177    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.49        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 319         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 5444        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012427822 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.79        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 319         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 5041        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010784376 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.09        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 319         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4799        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010391977 |\n",
      "|    clip_fraction        | 0.0419      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.6         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 319          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4567         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064346045 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.757        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000742    |\n",
      "|    value_loss           | 17.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 319         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4459        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011752548 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.23        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 319         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4391        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010560796 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.05        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 319         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4302        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009445673 |\n",
      "|    clip_fraction        | 0.0323      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.19        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00116    |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 500       |\n",
      "|    ep_rew_mean          | 319       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 4198      |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 19        |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0115845 |\n",
      "|    clip_fraction        | 0.0959    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.4      |\n",
      "|    explained_variance   | 0.813     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.14      |\n",
      "|    n_updates            | 90        |\n",
      "|    policy_gradient_loss | -0.00472  |\n",
      "|    value_loss           | 12.7      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 319          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4162         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059155095 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.04         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    value_loss           | 14.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 319         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4112        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010242403 |\n",
      "|    clip_fraction        | 0.0571      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.76        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 319         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4079        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006914782 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.000258   |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from src.mine_evac_env import MineEvacEnv\n",
    "import os\n",
    "\n",
    "# 项目根目录\n",
    "project_root = os.path.dirname(os.path.abspath(\"./mineEvac-python\"))\n",
    "layout_path = os.path.join(project_root, \"layout\", \"baseline.json\")\n",
    "\n",
    "def make_env():\n",
    "    return MineEvacEnv(layout_path=layout_path, max_steps=500)\n",
    "\n",
    "# 向量化环境（多进程并行）\n",
    "env = make_vec_env(make_env, n_envs=4)\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=100_000)\n",
    "\n",
    "model.save(os.path.join(project_root, \"models\", \"ppo_mine_evac_baseline\"))\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab1ea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs shape: (9,)\n",
      "obs: [0.01123596 0.42857143 0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "t=0, action=4, reward=-1.0, terminated=False, truncated=False\n",
      "t=1, action=1, reward=-1.0, terminated=False, truncated=False\n",
      "t=2, action=0, reward=-1.0, terminated=False, truncated=False\n",
      "t=3, action=0, reward=-1.0, terminated=False, truncated=False\n",
      "t=4, action=0, reward=-1.0, terminated=False, truncated=False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.mine_evac_env import MineEvacEnv\n",
    "\n",
    "project_root = os.path.dirname(os.path.abspath(\"./mineEvac-python\"))\n",
    "layout_path = os.path.join(project_root, \"layout\", \"baseline.json\")\n",
    "env = MineEvacEnv(layout_path=layout_path, max_steps=50)\n",
    "\n",
    "obs, info = env.reset()\n",
    "print(\"obs shape:\", obs.shape)\n",
    "print(\"obs:\", obs)\n",
    "\n",
    "for t in range(5):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    print(f\"t={t}, action={action}, reward={reward}, terminated={terminated}, truncated={truncated}\")\n",
    "    if terminated or truncated:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18dfeb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -0.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 4632     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import os\n",
    "\n",
    "from src.mine_evac_env import MineEvacEnv\n",
    "\n",
    "project_root = os.path.dirname(os.path.abspath(\"./mineEvac-python\"))\n",
    "layout_path = os.path.join(project_root, \"layout\", \"baseline.json\")\n",
    "\n",
    "def make_env():\n",
    "    return MineEvacEnv(layout_path=layout_path, max_steps=100)\n",
    "\n",
    "# 先用 1 个 env，调试更直观\n",
    "env = make_vec_env(make_env, n_envs=1)\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,        # 一定要 verbose=1 才有 stdout log\n",
    ")\n",
    "\n",
    "# 把训练步数调得超级小，先确认 log 是否正常打印\n",
    "model.learn(total_timesteps=2000)\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cf70b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -0.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 3262     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import os\n",
    "from src.mine_evac_env import MineEvacEnv\n",
    "\n",
    "project_root = os.path.dirname(os.path.abspath(\"./mineEvac-python\"))\n",
    "layout_path = os.path.join(project_root, \"layout\", \"baseline.json\")\n",
    "\n",
    "def make_env():\n",
    "    return MineEvacEnv(layout_path=layout_path, max_steps=100)\n",
    "\n",
    "env = make_vec_env(make_env, n_envs=1)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "model.learn(total_timesteps=2000)\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba039317",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m obs, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      3\u001b[0m     a \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "for t in range(5):\n",
    "    a = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(a)\n",
    "    if terminated or truncated:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "425b6ab9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'debug_plot_baseline_layout' from 'src.mine_evac_env' (/Users/szy/Library/Mobile Documents/com~apple~CloudDocs/2025/HiMCM-2025/HiMCMing/SGJ/mineEvac-python/src/mine_evac_env.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmine_evac_env\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m debug_plot_baseline_layout\n\u001b[1;32m      4\u001b[0m project_root \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./mineEvac-python\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      5\u001b[0m layout_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(project_root, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'debug_plot_baseline_layout' from 'src.mine_evac_env' (/Users/szy/Library/Mobile Documents/com~apple~CloudDocs/2025/HiMCM-2025/HiMCMing/SGJ/mineEvac-python/src/mine_evac_env.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from src.mine_evac_env import debug_plot_baseline_layout\n",
    "\n",
    "project_root = os.path.dirname(os.path.abspath(\"./mineEvac-python\"))\n",
    "layout_path = os.path.join(project_root, \"layout\", \"baseline.json\")\n",
    "\n",
    "debug_plot_baseline_layout(layout_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00842e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.9     |\n",
      "|    ep_rew_mean     | 20.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 5041     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 27.6       |\n",
      "|    ep_rew_mean          | 27.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3284       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00923134 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.686     |\n",
      "|    explained_variance   | -0.0114    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.96       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    value_loss           | 47.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.4        |\n",
      "|    ep_rew_mean          | 35.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3102        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009496527 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.665      |\n",
      "|    explained_variance   | 0.0838      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 45.1         |\n",
      "|    ep_rew_mean          | 45.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3038         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111736115 |\n",
      "|    clip_fraction        | 0.0963       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.632       |\n",
      "|    explained_variance   | 0.188        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0204      |\n",
      "|    value_loss           | 52.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 59.5       |\n",
      "|    ep_rew_mean          | 59.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2997       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 3          |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00868408 |\n",
      "|    clip_fraction        | 0.0916     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.601     |\n",
      "|    explained_variance   | 0.341      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 19.7       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    value_loss           | 58         |\n",
      "----------------------------------------\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# 创建环境\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# 创建模型\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# 训练模型\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# 保存与加载\n",
    "model.save(\"../models/ppo_cartpole\")\n",
    "model = PPO.load(\"../models/ppo_cartpole\", env=env)\n",
    "\n",
    "# 预测动作\n",
    "obs, _ = env.reset()\n",
    "action, _ = model.predict(obs, deterministic=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "754aa611",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2228020204.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    const mineflayer = require('mineflayer')\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "const mineflayer = require('mineflayer')\n",
    "const mineflayerViewer = require('prismarine-viewer').mineflayer\n",
    "\n",
    "const bot = mineflayer.createBot({\n",
    "  username: 'Bot'\n",
    "})\n",
    "\n",
    "bot.once('spawn', () => {\n",
    "  mineflayerViewer(bot, { port: 3000 }) // Start the viewing server on port 3000\n",
    "\n",
    "  // Draw the path followed by the bot\n",
    "  const path = [bot.entity.position.clone()]\n",
    "  bot.on('move', () => {\n",
    "    if (path[path.length - 1].distanceTo(bot.entity.position) > 1) {\n",
    "      path.push(bot.entity.position.clone())\n",
    "      bot.viewer.drawLine('path', path)\n",
    "    }\n",
    "  })\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa452be7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1712249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minestudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
